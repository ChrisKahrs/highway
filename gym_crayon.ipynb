{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Switch to hw4_env environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blackjack\n",
    "- Self Play\n",
    "- Reward Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ckahrs\\Anaconda3\\envs\\hw4_env\\lib\\site-packages\\gym\\utils\\play.py:323: DeprecationWarning: \u001b[33mWARN: `PlayPlot` is marked as deprecated and will be removed in the near future.\u001b[0m\n",
      "  \"`PlayPlot` is marked as deprecated and will be removed in the near future.\"\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym.utils.play import play, PlayPlot\n",
    "\n",
    "def callback(obs_t, obs_tp1, action, rew, terminated, truncated, info):\n",
    "       return [rew,]\n",
    "   \n",
    "plotter = PlayPlot(callback, 150, [\"reward\"])\n",
    "kta = {(100,):0,(119,):1}\n",
    "# Unsure why KTA is not working\n",
    "\n",
    "play(gym.make(\"Blackjack-v1\", render_mode=\"rgb_array\"), callback=plotter.callback, \n",
    "              keys_to_action=kta\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blackjack \n",
    "- human input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs: (12, 10, False)\n",
      "Reward:  0.0\n",
      "Terminated:  False\n",
      "truncated:  False\n",
      "info:  {}\n",
      "obs: (14, 10, False)\n",
      "Reward:  0.0\n",
      "Terminated:  False\n",
      "truncated:  False\n",
      "info:  {}\n",
      "obs: (19, 10, False)\n",
      "Reward:  0.0\n",
      "Terminated:  False\n",
      "truncated:  False\n",
      "info:  {}\n",
      "obs: (19, 10, False)\n",
      "Reward:  1.0\n",
      "Terminated:  True\n",
      "truncated:  False\n",
      "info:  {}\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym.utils.play import play, PlayPlot\n",
    "\n",
    "env = gym.make(\"Blackjack-v1\", render_mode=\"human\")\n",
    "\n",
    "obs, info = env.reset(seed=2)\n",
    "env.render()\n",
    "terminated = False\n",
    "while not terminated:\n",
    "    action = int(input(\"Enter action: \"))\n",
    "    obs, rew, terminated, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "    print(\"obs:\", obs)\n",
    "    print(\"Reward: \", rew)\n",
    "    print(\"Terminated: \", terminated)\n",
    "    print(\"truncated: \", truncated)\n",
    "    print(\"info: \", info)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial: https://gymnasium.farama.org/tutorials/blackjack_tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car Racing\n",
    "* human play\n",
    "* Reward plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ckahrs\\Anaconda3\\envs\\hw4_env\\lib\\site-packages\\gym\\utils\\play.py:323: DeprecationWarning: \u001b[33mWARN: `PlayPlot` is marked as deprecated and will be removed in the near future.\u001b[0m\n",
      "  \"`PlayPlot` is marked as deprecated and will be removed in the near future.\"\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym.utils.play import play, PlayPlot\n",
    "\n",
    "def callback(obs_t, obs_tp1, action, rew, terminated, truncated, info):\n",
    "       return [rew,]\n",
    "   \n",
    "plotter = PlayPlot(callback, 150, [\"reward\"])\n",
    "\n",
    "play(gym.make(\"CarRacing-v2\", render_mode=\"rgb_array\"), zoom=2, callback=plotter.callback, \n",
    "              keys_to_action={\n",
    "                                               \"w\": np.array([0, 0.7, 0]),\n",
    "                                               \"a\": np.array([-1, 0, 0]),\n",
    "                                               \"s\": np.array([0, 0, 1]),\n",
    "                                               \"d\": np.array([1, 0, 0]),\n",
    "                                               \"wa\": np.array([-1, 0.7, 0]),\n",
    "                                               \"dw\": np.array([1, 0.7, 0]),\n",
    "                                               \"ds\": np.array([1, 0, 1]),\n",
    "                                               \"as\": np.array([-1, 0, 1]),\n",
    "                                              }, noop=np.array([0,0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better human racing: python gymnasium/envs/box2d/car_racing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lunar Lander\n",
    "- unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reset() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23212\\2764569123.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LunarLander-v2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrender_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgravity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecordEpisodeStatistics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mkta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m119\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m97\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzoom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys_to_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: reset() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym.utils.play import play\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\", render_mode='rgb_array', gravity=-5.0)\n",
    "env = gym.wrappers.RecordEpisodeStatistics(env,500)\n",
    "env.reset()\n",
    "kta = {(100,):1,(119,):2, (97,):3}\n",
    "play(env, zoom=2, keys_to_action=kta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([-499.1459, -227.24275, -371.19315, -251.82076, -478.68826, -377.25903], maxlen=500)\n",
      "deque([229, 191, 140, 109, 215, 152], maxlen=500)\n"
     ]
    }
   ],
   "source": [
    "print(env.return_queue)\n",
    "print(env.length_queue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highway Gym\n",
    "* manual play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info:  {'speed': 25.0, 'crashed': False, 'action': 4, 'cost': 0.0}\n",
      "reward:  0.8666666666666667\n",
      "count:  0\n",
      "info:  {'speed': 25.0, 'crashed': False, 'action': 4, 'cost': 0.0}\n",
      "reward:  0.8666666666666667\n",
      "count:  1\n",
      "info:  {'speed': 23.511659807956104, 'crashed': False, 'action': 4, 'cost': 0.0}\n",
      "reward:  0.8269775948788295\n",
      "count:  2\n",
      "info:  {'speed': 20.600101345189188, 'crashed': False, 'action': 2, 'cost': 0.0}\n",
      "reward:  0.7493360358717117\n",
      "count:  3\n",
      "info:  {'speed': 20.102550259476153, 'crashed': False, 'action': 1, 'cost': 0.0}\n",
      "reward:  0.7360680069193641\n",
      "count:  4\n",
      "info:  {'speed': 20.01752463280233, 'crashed': False, 'action': 2, 'cost': 0.0}\n",
      "reward:  0.7338006568747288\n",
      "count:  5\n",
      "info:  {'speed': 20.002994753562064, 'crashed': False, 'action': 4, 'cost': 0.0}\n",
      "reward:  0.7334131934283218\n",
      "count:  6\n",
      "info:  {'speed': 20.000511768149366, 'crashed': False, 'action': 0, 'cost': 0.0}\n",
      "reward:  0.7333469804839831\n",
      "count:  7\n",
      "info:  {'speed': 20.000087455155587, 'crashed': False, 'action': 0, 'cost': 0.0}\n",
      "reward:  0.7333356654708156\n",
      "count:  8\n",
      "info:  {'speed': 20.000014945057146, 'crashed': False, 'action': 0, 'cost': 0.0}\n",
      "reward:  0.7333337318681905\n",
      "count:  9\n",
      "info:  {'speed': 20.000002553934433, 'crashed': False, 'action': 4, 'cost': 0.0}\n",
      "reward:  0.7333334014382515\n",
      "count:  10\n",
      "info:  {'speed': 20.000000436437347, 'crashed': False, 'action': 0, 'cost': 0.0}\n",
      "reward:  0.7333333449716627\n",
      "count:  11\n",
      "info:  {'speed': 20.00000007458201, 'crashed': False, 'action': 2, 'cost': 0.0}\n",
      "reward:  0.7333333353221869\n",
      "count:  12\n",
      "info:  {'speed': 20.00000001274519, 'crashed': False, 'action': 0, 'cost': 0.0}\n",
      "reward:  0.7333333336732051\n",
      "count:  13\n",
      "info:  {'speed': 20.000000002178, 'crashed': False, 'action': 0, 'cost': 0.0}\n",
      "reward:  0.7333333333914133\n",
      "count:  14\n",
      "info:  {'speed': 20.000000000372196, 'crashed': False, 'action': 4, 'cost': 0.0}\n",
      "reward:  0.7333333333432587\n",
      "count:  15\n",
      "info:  {'speed': 20.0000000000636, 'crashed': False, 'action': 4, 'cost': 0.0}\n",
      "reward:  0.7333333333350294\n",
      "count:  16\n",
      "info:  {'speed': 20.00000000001087, 'crashed': False, 'action': 0, 'cost': 0.0}\n",
      "reward:  0.7333333333336233\n",
      "count:  17\n",
      "info:  {'speed': 20.000000000001858, 'crashed': False, 'action': 1, 'cost': 0.0}\n",
      "reward:  0.7111111111111111\n",
      "count:  18\n",
      "info:  {'speed': 20.000000000000316, 'crashed': False, 'action': 4, 'cost': 0.0}\n",
      "reward:  0.7111111111111111\n",
      "count:  19\n",
      "info:  {'speed': 20.000000000000057, 'crashed': False, 'action': 0, 'cost': 0.0}\n",
      "reward:  0.7111111111111111\n",
      "count:  20\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 3, 'cost': 0.0}\n",
      "reward:  0.7111111111111111\n",
      "count:  21\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 1, 'cost': 0.0}\n",
      "reward:  0.7111111111111111\n",
      "count:  22\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 2, 'cost': 0.0}\n",
      "reward:  0.7111111111111111\n",
      "count:  23\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 1, 'cost': 0.0}\n",
      "reward:  0.7111111111111111\n",
      "count:  24\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 1, 'cost': 0.0}\n",
      "reward:  0.7111111111111111\n",
      "count:  25\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 1, 'cost': 0.0}\n",
      "reward:  0.7111111111111116\n",
      "count:  26\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 4, 'cost': 0.0}\n",
      "reward:  0.7111111111111116\n",
      "count:  27\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 3, 'cost': 0.0}\n",
      "reward:  0.7111111111111116\n",
      "count:  28\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 4, 'cost': 0.0}\n",
      "reward:  0.7111111111111116\n",
      "count:  29\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 4, 'cost': 0.0}\n",
      "reward:  0.7111111111111116\n",
      "count:  30\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 3, 'cost': 0.0}\n",
      "reward:  0.7111111111111116\n",
      "count:  31\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 3, 'cost': 0.0}\n",
      "reward:  0.7111111111111116\n",
      "count:  32\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 3, 'cost': 0.0}\n",
      "reward:  0.7111111111111116\n",
      "count:  33\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 1, 'cost': 0.0}\n",
      "reward:  0.7111111111111116\n",
      "count:  34\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 2, 'cost': 0.0}\n",
      "reward:  0.7111111111111116\n",
      "count:  35\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 1, 'cost': 0.0}\n",
      "reward:  0.7111111111111116\n",
      "count:  36\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 1, 'cost': 0.0}\n",
      "reward:  0.7111111111111116\n",
      "count:  37\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 4, 'cost': 0.0}\n",
      "reward:  0.7111111111111116\n",
      "count:  38\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 3, 'cost': 0.0}\n",
      "reward:  0.7111111111111116\n",
      "count:  39\n",
      "info:  {'speed': 20.000000000000014, 'crashed': False, 'action': 3, 'cost': 0.0}\n",
      "Total reward: 29.22405639238237\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import highway_env\n",
    "\n",
    "config = {\n",
    "    \"simulation_frequency\": 15,\n",
    "    \"show_trajectories\": False,\n",
    "    \"manual_control\": True,\n",
    "    \"observation\": {\n",
    "        \"type\": \"Kinematics\",\n",
    "        \"vehicles_count\": 15,\n",
    "        \"features\": [\"presence\", \"x\", \"y\", \"vx\", \"vy\", \"cos_h\", \"sin_h\"],\n",
    "        \"features_range\": {\n",
    "            \"x\": [-100, 100],\n",
    "            \"y\": [-100, 100],\n",
    "            \"vx\": [-20, 20],\n",
    "            \"vy\": [-20, 20]\n",
    "        },\n",
    "        \"absolute\": False,\n",
    "        \"order\": \"sorted\"\n",
    "    }\n",
    "}\n",
    "# env = gym.make('highway-fast-v0')\n",
    "env = gym.make('highway-v0')\n",
    "env.configure(config)\n",
    "# env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "\n",
    "total_reward = 0\n",
    "count = 0\n",
    "env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    obs, reward, done, info = env.step(env.action_space.sample())\n",
    "    print(\"info: \", info)\n",
    "    print(\"reward: \", reward)\n",
    "    print(\"count: \", count)\n",
    "    total_reward += reward\n",
    "    count += 1\n",
    "    env.render()\n",
    "    \n",
    "print(\"info: \", info)\n",
    "print(\"Total reward:\", total_reward)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues?\n",
    "- if you get RAND_LIMIT...Try this 'pip3 install box2d box2d-kengz'\n",
    "- Which Python on windows: python -c \"import sys; print(sys.executable)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('hw4_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6241628ca03169c539073f9270cd151db60cb14e39652deee86987017b204276"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
